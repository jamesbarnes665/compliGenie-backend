from typing import List, Dict, Any
import asyncio
from datetime import datetime

class PolicyGenerator:
    """
    Generates comprehensive AI policy content with detailed procedures and guidelines.
    Enhanced version with 2-3 paragraphs per section and step-by-step guidance.
    """
    
    async def generate(
        self, 
        company_name: str, 
        industry: str, 
        ai_tools: List[str], 
        employee_count: int
    ) -> Dict[str, Any]:
        """
        Generate comprehensive policy content structure for PDF generation.
        """
        
        # Format AI tools list
        tools_text = ", ".join(ai_tools) if ai_tools else "AI tools"
        
        # Generate policy content with expanded sections
        policy_data = {
            "title": f"Artificial Intelligence Usage Policy",
            "company_name": company_name,
            "effective_date": datetime.now().strftime("%B %d, %Y"),
            "sections": [
                {
                    "title": "Purpose and Scope",
                    "content": f"""This Artificial Intelligence (AI) Usage Policy establishes comprehensive guidelines and standards for the responsible use of AI technologies at {company_name}. As a {industry} company with {employee_count} employees, we recognize the transformative potential of AI while acknowledging the need for careful governance. This policy serves as the foundation for ethical, secure, and effective AI implementation across all departments and functions within our organization.

The rapid advancement of AI technologies presents both unprecedented opportunities and significant challenges. This policy addresses the need to harness AI's capabilities while mitigating risks related to data privacy, security, bias, and ethical considerations. It provides a framework for decision-making that balances innovation with responsibility, ensuring that our use of AI aligns with our corporate values and legal obligations.

This policy applies to all employees, contractors, consultants, temporary staff, interns, and third-party users who interact with AI systems on behalf of {company_name}. It covers the use of {tools_text} and any other AI technologies adopted by the organization, whether accessed through company-provided resources or personal devices used for business purposes. The scope includes AI usage for all business functions including but not limited to operations, marketing, sales, customer service, human resources, finance, and research and development.""",
                    "subsections": [
                        {
                            "title": "Policy Objectives",
                            "content": f"""The primary objectives of this policy are to: (1) Establish clear guidelines for appropriate AI use that protect {company_name}'s interests and reputation; (2) Ensure compliance with all applicable laws, regulations, and industry standards; (3) Protect sensitive data and intellectual property from unauthorized disclosure or misuse; (4) Promote ethical AI practices that respect privacy, fairness, and transparency; (5) Enable innovation while maintaining appropriate risk controls; (6) Provide clear accountability structures for AI-related decisions and outcomes; (7) Establish training requirements to ensure competent and responsible AI usage across the organization."""
                        },
                        {
                            "title": "Definitions and Key Terms",
                            "content": f"""For the purposes of this policy, the following definitions apply: 'Artificial Intelligence' refers to computer systems capable of performing tasks that typically require human intelligence, including but not limited to natural language processing, image recognition, decision-making, and pattern recognition. 'AI-Generated Content' means any text, images, code, or other materials created or substantially modified by AI systems. 'Sensitive Data' includes personally identifiable information (PII), protected health information (PHI), financial data, trade secrets, and any information classified as confidential by {company_name}. 'Approved AI Tools' refers to AI systems that have been evaluated and authorized by the IT department for business use."""
                        }
                    ]
                },
                {
                    "title": "Approved AI Tools and Technologies",
                    "content": f"""The following AI tools and technologies have been evaluated and approved for use within {company_name}: {tools_text}. Each tool has undergone rigorous assessment for security vulnerabilities, data handling practices, compliance with privacy regulations, and alignment with our business needs. The approval process considers factors including the vendor's security certifications, data retention policies, API security, user access controls, and compliance with industry standards such as SOC 2, ISO 27001, and GDPR requirements.

Employees must only use AI tools that have been officially approved through our technology review process. Any request to use new AI tools must be submitted to the IT department through the designated request portal, including a business justification, intended use cases, data types to be processed, and risk assessment. The review process typically takes 10-15 business days and includes security evaluation, legal review, cost analysis, and pilot testing where appropriate. Unauthorized use of AI tools may result in disciplinary action and potential security breaches that could harm the organization.

The use of personal or unapproved AI tools for company business is strictly prohibited, as these may not meet our security and compliance requirements. This prohibition extends to free versions of AI tools, browser extensions with AI capabilities, mobile AI applications, and any AI services accessed through personal accounts. Employees discovering useful AI tools should submit them for evaluation rather than using them independently. Regular audits will be conducted to ensure compliance with this policy, and network monitoring tools will flag unauthorized AI tool access.""",
                    "subsections": [
                        {
                            "title": "Tool-Specific Guidelines and Approved Use Cases",
                            "content": f"""Each approved AI tool has specific use cases, limitations, and guidelines that must be followed. Employees must complete tool-specific training before gaining access and must recertify annually. The following guidelines apply to our approved tools: For text generation tools (ChatGPT, Claude), approved uses include drafting initial content, brainstorming, research assistance, and code documentation, while prohibited uses include generating final customer communications without review, creating legal documents, or processing confidential data. For image generation tools (Midjourney, DALL-E), approved uses include creating concept art, marketing mockups, and internal presentations, while prohibited uses include creating images of real people, generating content for external use without legal review, or creating potentially offensive content. For code assistance tools (GitHub Copilot), approved uses include code completion, debugging assistance, and documentation generation, while prohibited uses include copying proprietary code patterns or implementing security-critical functions without review."""
                        },
                        {
                            "title": "New Tool Evaluation Process",
                            "content": f"""When requesting new AI tools, employees must follow this evaluation process: (1) Submit a formal request through the IT service portal including tool name, vendor information, intended use cases, and business justification; (2) Identify the types of data that will be processed and any integration requirements; (3) Provide cost estimates including licensing, training, and implementation expenses; (4) Participate in security assessment meetings and provide vendor security documentation; (5) Conduct pilot testing with a limited user group for 30 days; (6) Submit feedback and final recommendation report; (7) Await formal approval from the AI Governance Committee before proceeding with full implementation. The committee meets monthly and includes representatives from IT, Legal, Security, and business unit leaders."""
                        }
                    ]
                },
                {
                    "title": "Data Security and Privacy",
                    "content": f"""Protection of sensitive data is paramount when using AI technologies. {company_name} maintains a zero-tolerance policy for unauthorized disclosure of confidential information through AI systems. All employees must understand that AI systems may retain, analyze, and use input data for model training unless specifically configured otherwise. This means that any information entered into an AI system should be considered potentially public and permanent. Before using any AI tool, employees must carefully review the data classification of all information they intend to process and ensure it aligns with approved use cases.

Employees must never input the following types of information into AI systems unless specifically authorized and using approved, secure channels: Personally Identifiable Information (PII) including names, addresses, social security numbers, driver's license numbers, or any combination of data that could identify an individual; Financial information including credit card numbers, bank account details, salary information, or investment data; Protected Health Information (PHI) covered under HIPAA including medical records, diagnosis information, treatment plans, or insurance details; Proprietary business information including trade secrets, unreleased product plans, strategic initiatives, merger and acquisition details, or confidential financial performance data; Legal documents subject to attorney-client privilege or ongoing litigation holds; Source code, API keys, passwords, or technical specifications of proprietary systems; Customer lists, supplier agreements, or any third-party confidential information shared under NDA.

All AI-generated content must be treated as potentially public information and should undergo thorough review before any internal or external distribution. Employees must implement data minimization principles, sharing only the minimum information necessary to achieve the intended outcome. When collaborating with AI systems, use anonymized or synthetic data whenever possible, and always verify that outputs do not inadvertently contain or reveal sensitive information. Regular training on data classification and handling procedures is mandatory for all employees with AI access.""",
                    "subsections": [
                        {
                            "title": "Data Classification and Handling Procedures",
                            "content": f"""All data at {company_name} is classified into four categories that determine AI usage permissions: (1) Public Data - Information already in the public domain or approved for public release, freely usable with AI tools; (2) Internal Data - General business information not intended for public release but not containing sensitive elements, usable with approved AI tools with caution; (3) Confidential Data - Sensitive business information that could harm the company if disclosed, NOT to be used with AI tools unless specifically authorized; (4) Restricted Data - Highly sensitive information including PII, PHI, financial data, and legal documents, NEVER to be used with AI tools. Employees must verify data classification before any AI interaction using our data classification matrix available on the intranet. When in doubt, treat data as one level higher in sensitivity and consult with your manager or the Information Security team."""
                        },
                        {
                            "title": "Incident Response Procedures",
                            "content": f"""In the event of accidental disclosure of sensitive information to an AI system, employees must immediately: (1) Stop using the AI tool and preserve all evidence of the interaction; (2) Report the incident to the Information Security team within 1 hour via the security hotline or incident reporting system; (3) Document all sensitive information that was exposed, including data types, volume, and specific details; (4) Identify all individuals whose information may have been compromised; (5) Cooperate fully with the incident response team's investigation and remediation efforts; (6) Complete additional training as directed by the Security team. Failure to promptly report data exposure incidents may result in disciplinary action and increases the risk of regulatory penalties and reputational damage to {company_name}."""
                        }
                    ]
                },
                {
                    "title": "Acceptable Use Guidelines",
                    "content": f"""AI tools should be used to enhance productivity, improve decision-making, and support innovation while maintaining professional standards and ethical principles. At {company_name}, we encourage creative and beneficial uses of AI that align with our business objectives and values. Acceptable uses of AI include but are not limited to: drafting and editing business communications such as emails, reports, and presentations (with human review); conducting research and analysis to support decision-making and strategy development; generating ideas and creative content for marketing, product development, and problem-solving; automating routine tasks to improve efficiency and reduce human error; improving code quality through automated testing, documentation, and optimization suggestions; enhancing customer service through chatbots and response suggestions (with human oversight); analyzing data patterns and trends to identify opportunities and risks.

All AI-generated content must be reviewed, verified, and edited by qualified personnel before being used in any official capacity. Employees remain fully responsible for any content they create or distribute, regardless of AI assistance. This responsibility includes ensuring accuracy, appropriateness, legal compliance, and alignment with company standards. AI should be viewed as a tool to augment human capabilities, not replace human judgment. Critical decisions, sensitive communications, and high-stakes content must always involve human oversight and approval. Employees must clearly distinguish between AI-assisted and human-generated content when the distinction is material to the recipient or use case.

Prohibited uses of AI include but are not limited to: generating false or misleading information; creating content that violates copyright, trademark, or other intellectual property rights; producing material that is discriminatory, harassing, or offensive; making automated decisions about employment, credit, or other significant matters without human review; impersonating individuals or misrepresenting AI-generated content as human-created when disclosure is required; circumventing security controls or attempting to exploit AI systems; using AI for personal projects during work hours without authorization. Employees must also be aware of the limitations of AI systems, including potential biases, hallucinations, and errors, and must validate all AI outputs before relying on them for business decisions.""",
                    "subsections": [
                        {
                            "title": "Quality Assurance and Review Requirements",
                            "content": f"""All AI-generated content must undergo appropriate quality assurance before use. The level of review required depends on the content's purpose and audience: (1) Internal communications and drafts - Minimum self-review for accuracy and appropriateness; (2) External communications - Mandatory peer review and approval by communication owner; (3) Technical documentation - Technical review by subject matter expert and testing of any code or procedures; (4) Marketing content - Review by legal and brand teams for compliance and consistency; (5) Financial or legal content - Multiple reviews including department head approval and legal sign-off. Reviewers must verify factual accuracy, check for potential biases or inappropriate content, ensure compliance with regulations and policies, validate that sensitive information is properly protected, and confirm alignment with {company_name}'s brand voice and values. Documentation of the review process must be maintained for audit purposes."""
                        },
                        {
                            "title": "Ethical AI Usage Guidelines",
                            "content": f"""Employees must adhere to ethical principles when using AI: (1) Transparency - Disclose AI use when it materially affects the content or decision-making process; (2) Fairness - Actively work to identify and mitigate biases in AI outputs that could disadvantage any group; (3) Accountability - Take full responsibility for AI-assisted work and decisions; (4) Privacy - Respect individual privacy rights and data protection principles; (5) Beneficence - Use AI to create positive outcomes for stakeholders and society; (6) Non-maleficence - Avoid uses of AI that could cause harm or deception. When encountering ethical dilemmas, employees should consult with their manager and the Ethics Committee. Regular ethics training specific to AI use is required for all employees with AI access."""
                        }
                    ]
                },
                {
                    "title": "Compliance and Regulatory Requirements",
                    "content": f"""As a {industry} company, {company_name} must comply with extensive industry-specific regulations regarding AI use. The regulatory landscape for AI is rapidly evolving, with new laws and guidelines emerging at local, national, and international levels. Our compliance program ensures adherence to all applicable regulations including GDPR for data protection, CCPA for consumer privacy, HIPAA for healthcare information (if applicable), SOX for financial reporting, and industry-specific regulations. Compliance is not optional and violations can result in significant fines, legal liability, and reputational damage.

Key compliance requirements include maintaining detailed audit trails of all AI-assisted decisions that impact customers, employees, or business operations. These audit trails must capture input data, AI system used, output generated, human review conducted, and final decisions made. Transparency in AI-driven processes is mandatory, particularly for decisions affecting individuals' rights or interests. We must be able to explain how AI contributed to any decision and provide individuals with meaningful information about the logic involved. Protection against algorithmic bias and discrimination is critical, requiring regular testing and validation of AI systems to ensure fair treatment across all protected classes.

Data retention and deletion requirements vary by jurisdiction and data type. AI systems must not retain data longer than permitted by law or our data retention policies. Employees must understand that some AI systems may retain training data indefinitely, making them unsuitable for processing data subject to deletion requirements. International data protection regulations require special attention when using cloud-based AI services that may process data across borders. Always verify that AI tools comply with data localization requirements and have appropriate data processing agreements in place.""",
                    "subsections": [
                        {
                            "title": "Regulatory Compliance Procedures",
                            "content": f"""To ensure ongoing compliance, employees must follow these procedures: (1) Before using AI for any new use case, complete the Regulatory Impact Assessment form available on the compliance portal; (2) Maintain detailed logs of all AI interactions involving personal data or regulatory decisions; (3) Participate in quarterly compliance training updates focusing on new regulations and requirements; (4) Report any potential compliance issues immediately to the Compliance Officer; (5) Cooperate fully with internal and external audits of AI usage; (6) Stay informed about regulatory changes through the monthly compliance newsletter and team briefings. The Legal and Compliance teams maintain a regulatory matrix mapping specific requirements to AI use cases, which must be consulted before implementing new AI applications. Regular compliance audits will verify adherence to these procedures."""
                        },
                        {
                            "title": "Industry-Specific Requirements",
                            "content": f"""Given our operation in the {industry} sector, additional requirements apply: For healthcare-related AI use, all systems must be HIPAA-compliant with appropriate Business Associate Agreements; For financial services applications, AI must not be used for credit decisions without human review and must maintain explainability for regulatory examination; For HR applications, AI cannot be the sole factor in hiring, promotion, or termination decisions and must be regularly audited for bias; For customer-facing applications, clear disclosure of AI use is required and customers must have the option to request human intervention. Industry associations and regulatory bodies continue to develop specific guidance for AI use in {industry}, which will be incorporated into this policy as it becomes available. Employees should consult with the Compliance team when planning any AI implementation that may be subject to industry-specific regulations."""
                        }
                    ]
                },
                {
                    "title": "Intellectual Property and Attribution",
                    "content": f"""AI-generated content raises complex intellectual property (IP) questions that every employee must understand. The legal landscape regarding ownership of AI-generated content remains unsettled in many jurisdictions, creating potential risks for {company_name}. Current legal precedent suggests that AI-generated content may not be eligible for copyright protection in some jurisdictions since it lacks human authorship. However, human selection, arrangement, and modification of AI output may create copyrightable derivatives. Employees must assume that raw AI output provides no IP protection and must add substantial human creativity to establish ownership claims.

When using AI tools, employees must carefully verify that they are not inadvertently infringing on others' intellectual property rights. AI systems trained on vast datasets may reproduce copyrighted material, trademarks, or patented concepts without attribution. Before using AI-generated content, especially for external purposes, employees must conduct reasonable due diligence to ensure originality. This includes reverse image searches for AI-generated graphics, plagiarism checking for text content, and patent searches for technical innovations. Any content substantially similar to existing IP must not be used without proper licensing or permission.

Attribution requirements vary by use case and AI tool. Some AI platforms require attribution when their output is used commercially, while others permit unrestricted use. Employees must review and comply with the terms of service for each AI tool, maintaining records of which tools were used to generate specific content. When AI assistance materially contributes to work products, appropriate disclosure may be required, particularly in academic publications, patent applications, or creative works. {company_name}'s IP resulting from AI-assisted work remains company property, but employees must document the AI's role to defend against potential challenges.""",
                    "subsections": [
                        {
                            "title": "IP Protection Procedures",
                            "content": f"""To protect {company_name}'s intellectual property when using AI: (1) Never input proprietary algorithms, unique business processes, or confidential methodologies into public AI systems; (2) Document all human contributions to AI-assisted work, including prompts, selections, arrangements, and modifications; (3) Use AI-generated content as inspiration or starting points rather than final products; (4) Add company watermarks, metadata, or other identifying markers to AI-assisted creations; (5) Register important works with appropriate IP offices, clearly documenting the human creative elements; (6) Maintain chain-of-custody documentation for all AI-assisted innovations that may lead to patents or trade secrets; (7) Use company-approved AI instances with enterprise agreements that clarify IP ownership when available. The Legal department provides IP assessment services for high-value AI-assisted creations and can advise on protection strategies."""
                        },
                        {
                            "title": "Third-Party IP Respect",
                            "content": f"""Respecting others' intellectual property is essential when using AI: (1) Never use AI to deliberately copy or mimic copyrighted works, artistic styles, or proprietary designs; (2) Avoid prompts that reference specific copyrighted characters, brands, or works unless for legally permissible purposes; (3) Conduct clearance searches before using AI-generated content that resembles known works; (4) Obtain appropriate licenses when incorporating third-party content into AI training or prompts; (5) Respect trademark rights by avoiding AI-generated content that could cause consumer confusion; (6) Honor confidentiality agreements by not using others' confidential information in AI systems; (7) Document good-faith efforts to avoid infringement for legal defense purposes. When uncertain about potential IP conflicts, consult with the Legal department before proceeding. Regular training on IP considerations in AI use is mandatory for all content creators and developers."""
                        }
                    ]
                },
                {
                    "title": "Monitoring and Enforcement",
                    "content": f"""{company_name} reserves the right to monitor the use of AI tools to ensure compliance with this policy, applicable laws, and security requirements. Monitoring activities are conducted in accordance with local privacy laws and employee agreements, focusing on protecting company assets and ensuring appropriate use rather than surveilling individual productivity. Technical controls include network traffic analysis to identify unauthorized AI tool access, data loss prevention (DLP) systems to detect sensitive information being sent to AI platforms, and API usage monitoring for approved tools to identify unusual patterns or potential security incidents.

Violations of this AI usage policy will be taken seriously and addressed promptly. The disciplinary process is progressive and proportionate to the severity and frequency of violations. First-time minor violations typically result in coaching and additional training to ensure understanding of policy requirements. Repeated violations or single instances of serious misconduct may result in formal warnings, suspension of AI tool access, performance improvement plans, suspension without pay, or termination of employment. Violations that result in data breaches, regulatory fines, or significant reputational damage may lead to immediate termination and potential legal action to recover damages.

All employees are expected to report suspected violations of this policy to their supervisor, Human Resources, or the Compliance department. Reports can be made through our anonymous ethics hotline if preferred. {company_name} maintains a strict non-retaliation policy protecting good-faith reporters from any adverse employment actions. Managers who become aware of potential violations must escalate them immediately and may face discipline for failing to report or address known violations. Regular audits of AI usage will be conducted by the Internal Audit team, with findings reported to executive management and the Board of Directors.""",
                    "subsections": [
                        {
                            "title": "Monitoring Procedures and Employee Rights",
                            "content": f"""AI usage monitoring at {company_name} follows these principles and procedures: (1) Monitoring is conducted for legitimate business purposes including security, compliance, and policy enforcement; (2) Employees are notified of monitoring through this policy and system access agreements; (3) Personal use of company systems is discouraged and may be subject to monitoring; (4) Monitoring data is retained for 90 days unless required for investigation or legal purposes; (5) Access to monitoring data is restricted to authorized personnel with legitimate need-to-know; (6) Employees may request information about monitoring that affects them, subject to investigation confidentiality; (7) Monitoring practices are regularly reviewed by Legal and HR to ensure compliance with evolving privacy laws. The company uses automated tools to flag potential violations, but human review is required before any disciplinary action. Employees have the right to explain apparent violations before formal discipline is imposed."""
                        },
                        {
                            "title": "Violation Response and Remediation",
                            "content": f"""When policy violations are identified, the following response process applies: (1) Initial Assessment - Security and Compliance teams evaluate the severity and impact of the violation; (2) Immediate Containment - Access may be suspended to prevent further violations or damage; (3) Investigation - Fact-finding to understand the full scope and intent of the violation; (4) Employee Notification - Inform the employee of the alleged violation and provide opportunity to respond; (5) Disciplinary Decision - HR and management determine appropriate consequences based on severity and history; (6) Remediation - Address any damage caused and implement controls to prevent recurrence; (7) Documentation - Maintain records of violations and responses for consistency and legal purposes; (8) Training - Require additional training focused on the specific policy areas violated; (9) Follow-up - Monitor for continued compliance and successful behavior change. The goal is corrective action that protects {company_name} while helping employees succeed."""
                        }
                    ]
                },
                {
                    "title": "Training and Support",
                    "content": f"""Comprehensive training is essential for safe and effective AI use at {company_name}. All employees who will use AI tools must complete mandatory training before gaining access, with ongoing education required to maintain proficiency and awareness of evolving best practices. The initial training program covers five core modules: (1) AI Fundamentals - Understanding capabilities and limitations of AI technology; (2) Company Policy - Detailed review of this policy and its practical applications; (3) Tool-Specific Training - Hands-on instruction for each approved AI platform; (4) Security and Privacy - Data protection requirements and incident response procedures; (5) Ethics and Compliance - Responsible AI use and regulatory requirements. Training is delivered through a combination of online modules, instructor-led sessions, and hands-on workshops totaling 8 hours for initial certification.

Ongoing support ensures employees can effectively leverage AI while maintaining compliance. The AI Center of Excellence provides resources including a comprehensive knowledge base with FAQs, best practices, and use case examples; weekly office hours with AI experts for guidance on specific projects; a peer mentoring program pairing experienced AI users with newcomers; regular lunch-and-learn sessions showcasing successful AI implementations; and a dedicated Slack channel for real-time support and community discussion. The IT helpdesk offers technical support for approved AI tools, including access issues, integration problems, and performance optimization.

Continuous learning opportunities keep employees current with AI developments. Quarterly update training is mandatory, covering new features in approved tools, emerging security threats and mitigation strategies, regulatory changes affecting AI use, and lessons learned from incidents and successes. Advanced training tracks are available for power users and those seeking to expand their AI capabilities. {company_name} supports relevant external training and certification programs, with tuition reimbursement available for approved courses. Employees are encouraged to share their learning through internal presentations and documentation, building our collective AI expertise.""",
                    "subsections": [
                        {
                            "title": "Training Requirements and Certification",
                            "content": f"""Specific training requirements apply based on role and AI usage level: (1) Basic Users - 4-hour foundational training covering policy, security, and basic tool usage, with annual 1-hour refresher; (2) Regular Users - 8-hour comprehensive training including all modules and hands-on practice, with quarterly 2-hour updates; (3) Power Users - 16-hour advanced training including API usage, automation, and advanced features, with monthly skill-building sessions; (4) AI Champions - 40-hour train-the-trainer program to support colleagues, with ongoing professional development requirements. Certification is valid for one year and requires passing a comprehensive assessment with 80% or higher score. Employees must complete recertification before expiration to maintain access. Those who fail recertification have one retake opportunity before requiring full retraining. Managers receive reports on their team's training compliance and must ensure timely completion."""
                        },
                        {
                            "title": "Support Resources and Escalation",
                            "content": f"""Multiple support channels ensure employees can get help when needed: (1) Self-Service - Comprehensive wiki with searchable articles, video tutorials, and template library available 24/7; (2) Peer Support - AI Users group on internal social platform for community assistance and best practice sharing; (3) IT Helpdesk - Technical support via ticketing system with 4-hour response SLA for standard issues; (4) AI Center of Excellence - Strategic guidance and complex use case support with 24-hour response time; (5) Emergency Hotline - For security incidents or critical issues requiring immediate assistance; (6) Manager Escalation - For policy clarifications or exception requests requiring management approval. Support requests are tracked to identify common issues and improve training materials. The AI Governance Committee reviews support metrics monthly to ensure adequate resources and identify improvement opportunities. Employees providing exceptional peer support are recognized through the company recognition program."""
                        }
                    ]
                }
            ]
        }
        
        return policy_data